{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alcala09/bankruptcyNeuralNetwork/blob/main/UCLA_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZeYDtSZl9ot"
      },
      "outputs": [],
      "source": [
        "#todo:\n",
        "#logistic regression\n",
        "#svm\n",
        "#neural network\n",
        "#knn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQpvkH4TPWX6",
        "outputId": "fdf95ce1-e71e-4750-9c0b-203533ac41ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from sklearn.metrics import classification_report\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt # this is used for the plot the graph\n",
        "import os\n",
        "import seaborn as sns # used for plot interactive graph.\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn import metrics\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import sklearn.metrics.cluster as smc\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "from matplotlib import pyplot\n",
        "import itertools\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "Ujvze2RiPulA",
        "outputId": "fa489450-fbcf-4ff1-ab80-d42881405215"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-2c943b73062e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/UCLA Project/Proj/american_bankruptcy.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdf_orig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'X1'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'current assets'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"X2\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'costs of good sold'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'X3'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'depreciation and amoritzation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'X4'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"EBITDA\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"X5\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"inventory\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"X6\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"net income\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"X7\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"total receivables\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"X8\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"market value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"X9\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"net sales\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"X10\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"total assets\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"X11\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"total long-term debt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"X12\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"EBIT\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"X13\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"gross profit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"X14\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"total current liabilities\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"X15\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"retained earnings\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"X16\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"total revenue\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"X17\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"total liabilities\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"X18\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"total operatin expenses\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/UCLA Project/Proj/american_bankruptcy.csv'"
          ]
        }
      ],
      "source": [
        "df_orig = pd.read_csv(\"/content/drive/MyDrive/UCLA Project/Proj/american_bankruptcy.csv\")\n",
        "df  = df_orig.rename(columns={'X1': 'current assets', \"X2\": 'costs of good sold', 'X3': 'depreciation and amoritzation', 'X4': \"EBITDA\", \"X5\":\"inventory\", \"X6\": \"net income\", \"X7\": \"total receivables\", \"X8\":\"market value\", \"X9\": \"net sales\", \"X10\":\"total assets\", \"X11\": \"total long-term debt\", \"X12\":\"EBIT\", \"X13\":\"gross profit\", \"X14\":\"total current liabilities\", \"X15\":\"retained earnings\", \"X16\":\"total revenue\", \"X17\":\"total liabilities\", \"X18\": \"total operatin expenses\"})\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjUMB-s6aAJK"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6hLW1GXWXO4"
      },
      "outputs": [],
      "source": [
        "df['status_label'] = df[\"status_label\"].replace([\"alive\", \"failed\"], [1,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLcLkLZTZ0KQ"
      },
      "outputs": [],
      "source": [
        "df = df.sort_values(by = \"status_label\", ascending = True)\n",
        "df = df.head(10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kt587BrWAtl"
      },
      "outputs": [],
      "source": [
        "df = df.drop([\"year\", \"company_name\"], axis = 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQl9nH8IL-yM"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3-Y5Wp4KTf6"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "def remove_rows_with_outliers(df, z_threshold=3, exclude_column=None):\n",
        "    if exclude_column is not None:\n",
        "        columns_to_check = df.columns[df.columns != exclude_column]\n",
        "    else:\n",
        "        columns_to_check = df.columns\n",
        "\n",
        "    z_scores = np.abs(stats.zscore(df[columns_to_check]))\n",
        "    row_outliers = np.any(z_scores > z_threshold, axis=1)\n",
        "    filtered_df = df[~row_outliers]\n",
        "    return filtered_df\n",
        "#df = remove_rows_with_outliers(df, z_threshold=3, exclude_column = \"status_label\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InIsh16wP6UE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def remove_rows_above_threshold(dataframe, column, threshold):\n",
        "    # Copy the original DataFrame to avoid modifying it directly\n",
        "    df = dataframe.copy()\n",
        "\n",
        "    # Filter rows based on the specified column and threshold\n",
        "    df = df[df[column] <= threshold]\n",
        "\n",
        "    # Reset the index after removing rows\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsVgMCQmboet"
      },
      "outputs": [],
      "source": [
        "# for i in range(2):\n",
        "#   df = remove_rows_with_outliers(df, z_threshold=3, exclude_column = \"status_label\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZXSLzJmQaRn"
      },
      "outputs": [],
      "source": [
        "# df = remove_rows_above_threshold(df, \"current assets\", 1000)\n",
        "# df = remove_rows_above_threshold(df, \"costs of good sold\", 1000)\n",
        "# df = remove_rows_above_threshold(df, \"depreciation and amoritzation\", 100)\n",
        "# df = remove_rows_above_threshold(df, \"inventory\", 100)\n",
        "# df = remove_rows_above_threshold(df, \"total receivables\", 200)\n",
        "# df = remove_rows_above_threshold(df, \"net sales\", 1500)\n",
        "# df = remove_rows_above_threshold(df, \"total assets\", 1500)\n",
        "# df = remove_rows_above_threshold(df, \"gross profit\", 60000)\n",
        "# df = remove_rows_above_threshold(df, \"total current liabilities\", 300)\n",
        "# df = remove_rows_above_threshold(df, \"total revenue\", 2000)\n",
        "# df = remove_rows_above_threshold(df, \"total liabilities\", 1000)\n",
        "# df = remove_rows_above_threshold(df, \"total operatin expenses\", 1000)\n",
        "\n",
        "# #market value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eP_JaPmw_mmG"
      },
      "outputs": [],
      "source": [
        "df[\"status_label\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1KGjrlkLg6s"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNpejz6ocALv"
      },
      "outputs": [],
      "source": [
        "df[\"status_label\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qrEYdU2NKTa"
      },
      "outputs": [],
      "source": [
        "#df['status_label'] = df[\"status_label\"].replace([0, 1], [1,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugG2r6-raSgk"
      },
      "outputs": [],
      "source": [
        "Y = df[\"status_label\"].values\n",
        "X = df.drop(\"status_label\", axis  =1)\n",
        "X = X.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aa3kI_CylZiG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWNNoUL8-PyF"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "assert sys.version_info >= (3, 5) # python>=3.5\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\" # sklearn >= 0.20\n",
        "\n",
        "import numpy as np #numerical package in python\n",
        "import os\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt #plotting package\n",
        "\n",
        "#matplotlib magic for inline figures\n",
        "%matplotlib inline\n",
        "import matplotlib # plotting library\n",
        "import matplotlib.pyplot as plt\n",
        "corr_matrix = df.corr()\n",
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "ROOT_DIR = \".\"\n",
        "IMAGES_PATH = os.path.join(ROOT_DIR, \"images\")\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "# scatter_matrix(df_orig, figsize=(30, 20))\n",
        "\n",
        "\n",
        "\n",
        "# def save_fig(fig_name, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "#     '''\n",
        "#         plt.savefig wrapper. refer to\n",
        "#         https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.savefig.html\n",
        "#     '''\n",
        "#     path = os.path.join(IMAGES_PATH, fig_name + \".\" + fig_extension)\n",
        "#     print(\"Saving figure\", fig_name)\n",
        "#     if tight_layout:\n",
        "#         plt.tight_layout()\n",
        "#     plt.gca().set_aspect('equal')\n",
        "#     plt.savefig(path, format=fig_extension, dpi=resolution)\n",
        "# save_fig(\"scatter_matrix_plot\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gk7WLN4SCYpe"
      },
      "outputs": [],
      "source": [
        "def save_fig(fig_name, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    '''\n",
        "        plt.savefig wrapper. refer to\n",
        "        https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.savefig.html\n",
        "    '''\n",
        "    path = os.path.join(IMAGES_PATH, fig_name + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_name)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.gca().set_aspect('equal')\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnTEzXElJoyo"
      },
      "outputs": [],
      "source": [
        "scaler = preprocessing.StandardScaler()\n",
        "scaler.fit(X)\n",
        "X_scaled = scaler.transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKi9hqHwkRte"
      },
      "outputs": [],
      "source": [
        "train_X, test_X, train_Y, test_Y = train_test_split(X_scaled, Y, test_size = 0.2, random_state = 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQGAiqd7Gzjs"
      },
      "outputs": [],
      "source": [
        "#it seems like the optimal lambda value is 65.\n",
        "pd.DataFrame(train_X).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJ6uSXI0lzDK"
      },
      "outputs": [],
      "source": [
        "print(train_X.shape)\n",
        "print(train_Y.shape)\n",
        "print(test_X.shape)\n",
        "print(test_Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KodJCzaQ-EWO"
      },
      "outputs": [],
      "source": [
        "#logistic regression with no regularization\n",
        "model = 0;\n",
        "model = LogisticRegression()\n",
        "model.fit(train_X, train_Y)\n",
        "test_Y_hat = model.predict(test_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjOJargS_KbC"
      },
      "outputs": [],
      "source": [
        "test_Y_hat_cat = 1 * (test_Y_hat > 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b05JBB82AJ61"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(test_Y_hat_cat).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwjwGEczASSA"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(test_Y).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsQv0FGsHTWu"
      },
      "outputs": [],
      "source": [
        "def print_4_metrics(target_test, predicted):\n",
        "  print(\"%-12s %f\" % ('Accuracy:', metrics.accuracy_score(target_test,predicted)))\n",
        "  print(\"%-12s %f\" % ('Precision:', metrics.precision_score(target_test, predicted,labels=None, pos_label=1, average='binary', sample_weight=None)))\n",
        "  print(\"%-12s %f\" % ('Recall:', metrics.recall_score(target_test, predicted,labels=None, pos_label=1, average='binary', sample_weight=None)))\n",
        "  print(\"%-12s %f\" % ('F1 Score:', metrics.f1_score(target_test, predicted,labels=None, pos_label=1, average='binary', sample_weight=None)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "di-yZrF4A2ZL"
      },
      "outputs": [],
      "source": [
        "#logistic regression classification report before any regularization\n",
        "print(classification_report(test_Y, test_Y_hat_cat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90jNN84cFX9R"
      },
      "outputs": [],
      "source": [
        "def draw_confusion_matrix(y, yhat, classes, title = \"confusion matrix\"):\n",
        "    '''\n",
        "        Draws a confusion matrix for the given target and predictions\n",
        "        Adapted from scikit-learn and discussion example.\n",
        "    '''\n",
        "    plt.cla()\n",
        "    plt.clf()\n",
        "    matrix = confusion_matrix(y, yhat)\n",
        "    plt.imshow(matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    num_classes = len(classes)\n",
        "    plt.xticks(np.arange(num_classes), classes, rotation=90)\n",
        "    plt.yticks(np.arange(num_classes), classes)\n",
        "\n",
        "    fmt = 'd'\n",
        "    thresh = matrix.max() / 2.\n",
        "    for i, j in itertools.product(range(matrix.shape[0]), range(matrix.shape[1])):\n",
        "        plt.text(j, i, format(matrix[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if matrix[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8BXbdL-BNbJ"
      },
      "outputs": [],
      "source": [
        "# Plot ROC curve and report area under ROC\n",
        "# use metrics.roc_curve(your y_test, predicted probabilities for y_test)\n",
        "log_score = model.predict_proba(test_X)[:,1]\n",
        "fpr_log_reg, tpr_log_reg, thresholds = metrics.roc_curve(test_Y,log_score)\n",
        "print(\"Logistic Model Performance Results:\\n\")\n",
        "pyplot.figure(1)\n",
        "pyplot.plot(fpr_log_reg, tpr_log_reg, color='orange', lw=1)\n",
        "pyplot.title(\"ROC curve: Log Reg before any regularization\")\n",
        "pyplot.xlabel('FPR')\n",
        "pyplot.ylabel('TPR')\n",
        "save_fig(\"roc curve log reg no reg\")\n",
        "aucroc = metrics.auc(fpr_log_reg, tpr_log_reg)\n",
        "print('AUC of ROC: ', aucroc)\n",
        "save_fig(\"confusion matrix log reg no reg\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GwqN1vqE-hL"
      },
      "outputs": [],
      "source": [
        "# report auc\n",
        "# use metrics.auc(fpr, tpr)\n",
        "\n",
        "draw_confusion_matrix(test_Y, test_Y_hat_cat, [1,0], \"Confusion Matrix: logistic regression with no regularization\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRzitqfaCFgw"
      },
      "outputs": [],
      "source": [
        "#logistic regression with L1(Lasso) regularization\n",
        "lambdas = [70, 80, 90, 100]\n",
        "for l in lambdas:\n",
        "  model = 0;\n",
        "  model = LogisticRegression(penalty = \"l1\", C = 1/l, solver = \"liblinear\")\n",
        "  model.fit(train_X, train_Y)\n",
        "  test_Y_hat = model.predict(test_X)\n",
        "  test_Y_hat_cat = 1* (test_Y_hat) > 0.5\n",
        "  print(\"lambda = \" + str(l) + \":\")\n",
        "  print_4_metrics(test_Y, test_Y_hat_cat)\n",
        "  draw_confusion_matrix(test_Y, test_Y_hat_cat, [1,0])\n",
        "  print()\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYOkrxZmOf5b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "896CguE2uHwh"
      },
      "outputs": [],
      "source": [
        "#it appears that the optimal lambda is 65.\n",
        "model = 0;\n",
        "model = LogisticRegression(penalty = \"l1\", C = 1/65, solver = \"liblinear\")\n",
        "model.fit(train_X, train_Y)\n",
        "test_Y_hat = model.predict(test_X)\n",
        "test_Y_hat_cat = 1* (test_Y_hat) > 0.5\n",
        "print(\"lambda = \" + str(65) + \":\")\n",
        "print_4_metrics(test_Y, test_Y_hat_cat)\n",
        "print(classification_report(test_Y, test_Y_hat_cat))\n",
        "draw_confusion_matrix(test_Y, test_Y_hat_cat, [1,0],\"confusion matrix log reg l1 reg(lambda = 65)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KwUGpuQzmI3"
      },
      "outputs": [],
      "source": [
        "log_score = model.predict_proba(test_X)[:,1]\n",
        "fpr_log_reg, tpr_log_reg, thresholds = metrics.roc_curve(test_Y,log_score)\n",
        "print(\"Logistic Model Performance Results:\\n\")\n",
        "pyplot.figure(1)\n",
        "pyplot.plot(fpr_log_reg, tpr_log_reg, color='orange', lw=1)\n",
        "pyplot.title(\"ROC curve: Log Reg with l1 regularization\")\n",
        "pyplot.xlabel('FPR')\n",
        "pyplot.ylabel('TPR')\n",
        "save_fig(\"roc curve log reg l1 reg\")\n",
        "aucroc = metrics.auc(fpr_log_reg, tpr_log_reg)\n",
        "print('AUC of ROC: ', aucroc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O76UOuNOBg6N"
      },
      "source": [
        "#SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5vjHRaDBfKW"
      },
      "outputs": [],
      "source": [
        "model = 0;\n",
        "model = SVC(probability = True)\n",
        "model.fit(train_X, train_Y)\n",
        "test_Y_hat = model.predict(test_X)\n",
        "test_Y_hat_cat = 1*(test_Y_hat > 0.5)\n",
        "svm_score = model.predict_proba(test_X)[:,1]\n",
        "print_4_metrics(test_Y, test_Y_hat_cat)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHfC4WQcDwh8"
      },
      "outputs": [],
      "source": [
        "print(classification_report(test_Y, test_Y_hat_cat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NM25RC0WCZtP"
      },
      "outputs": [],
      "source": [
        "draw_confusion_matrix(test_Y, test_Y_hat_cat, [1,0], \"confusion matrix: SVM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0dGbcL2XWFV"
      },
      "outputs": [],
      "source": [
        "svm_score = model.predict_proba(test_X)[:,1]\n",
        "fpr_svm, tpr_svm, thresholds = metrics.roc_curve(test_Y,log_score)\n",
        "print(\"SVM Performance Results:\\n\")\n",
        "pyplot.figure(1)\n",
        "pyplot.plot(fpr_svm, tpr_svm, color='orange', lw=1)\n",
        "pyplot.title(\"ROC curve SVM: \")\n",
        "pyplot.xlabel('FPR')\n",
        "pyplot.ylabel('TPR')\n",
        "save_fig(\"roc curve SVM l1 reg\")\n",
        "aucroc = metrics.auc(fpr_svm, tpr_svm)\n",
        "print('AUC of ROC: ', aucroc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaA4AyTskGhw"
      },
      "source": [
        "#KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38FgFgEpkFNn"
      },
      "outputs": [],
      "source": [
        "k_values = [1,2,3,4,5,7,9,10,20,200]\n",
        "\n",
        "for k in k_values:\n",
        "  model = 0;\n",
        "  model = KNeighborsClassifier(n_neighbors = k)\n",
        "  model.fit(train_X, train_Y)\n",
        "  test_Y_hat = model.predict(test_X)\n",
        "  test_Y_hat_cat = 1* (test_Y_hat > .5)\n",
        "  print(\"k = \" + str(k))\n",
        "  print_4_metrics(test_Y, test_Y_hat_cat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjouA67Wmjb5"
      },
      "outputs": [],
      "source": [
        "#it seems like the optimal k is 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSOKCKBvml1i"
      },
      "outputs": [],
      "source": [
        "model = 0;\n",
        "model = KNeighborsClassifier(n_neighbors = 3)\n",
        "model.fit(train_X, train_Y)\n",
        "test_Y_hat = model.predict(test_X)\n",
        "test_Y_hat_cat = 1* (test_Y_hat > .5)\n",
        "print_4_metrics(test_Y, test_Y_hat_cat)\n",
        "print(classification_report(test_Y, test_Y_hat_cat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuyFLXN7nbR-"
      },
      "outputs": [],
      "source": [
        "draw_confusion_matrix(test_Y, test_Y_hat_cat, [1,0], \"confusion matrix KNN: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ju9YfAJSntZ-"
      },
      "outputs": [],
      "source": [
        "knn_score = model.predict_proba(test_X)[:,1]\n",
        "fpr_knn, tpr_knn, thresholds = metrics.roc_curve(test_Y,knn_score)\n",
        "print(\"KNN Performance Results:\\n\")\n",
        "pyplot.figure(1)\n",
        "pyplot.plot(fpr_knn, tpr_knn, color='orange', lw=1)\n",
        "pyplot.title(\"ROC curve: \")\n",
        "pyplot.xlabel('FPR')\n",
        "pyplot.ylabel('TPR')\n",
        "save_fig(\"roc curve KNN\")\n",
        "aucroc = metrics.auc(fpr_knn, tpr_knn)\n",
        "print('AUC of ROC: ', aucroc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20i-T3OZo8xp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O81SYc8po-Mb"
      },
      "source": [
        "#neural network (FOR THE LOVE OF GOD DO NOT RUN THIS ON COLAB IT TAKES FOREVER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otVQ5zwYo_Lu"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = 0;\n",
        "model = Sequential();\n",
        "model.add(Dense(20, activation = \"relu\"))\n",
        "model.add(Dense(20, activation = \"relu\"))\n",
        "model.add(Dense(1, activation = \"sigmoid\"));\n",
        "model.compile(loss = \"binary_crossentropy\")\n",
        "model.fit(train_X, train_Y, epochs = 10000, verbose  = 0)\n",
        "J = model.history.history[\"loss\"]\n",
        "plt.plot(J)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qRYQweJrp5Z"
      },
      "outputs": [],
      "source": [
        "test_Y_hat = model.predict(test_X)\n",
        "test_Y_hat_cat = 1* (test_Y_hat > 0.5)\n",
        "print(classification_report(test_Y, test_Y_hat_cat))\n",
        "# 63/63 [==============================] - 0s 1ms/step\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#            0       0.55      0.83      0.66      1042\n",
        "#            1       0.59      0.27      0.37       958\n",
        "\n",
        "#     accuracy                           0.56      2000\n",
        "#    macro avg       0.57      0.55      0.52      2000\n",
        "# weighted avg       0.57      0.56      0.52      2000\n",
        "\n",
        "#layer 1: 10 node relu\n",
        "# 63/63 [==============================] - 0s 2ms/step\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#            0       0.72      0.52      0.61      1042\n",
        "#            1       0.60      0.78      0.68       958\n",
        "\n",
        "#     accuracy                           0.65      2000\n",
        "#    macro avg       0.66      0.65      0.64      2000\n",
        "# weighted avg       0.66      0.65      0.64      2000\n",
        "\n",
        "#layer 1: 20 node relu\n",
        "# 63/63 [==============================] - 0s 2ms/step\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#            0       0.70      0.66      0.68      1042\n",
        "#            1       0.65      0.69      0.67       958\n",
        "\n",
        "#     accuracy                           0.67      2000\n",
        "#    macro avg       0.67      0.68      0.67      2000\n",
        "# weighted avg       0.68      0.67      0.67      2000\n",
        "\n",
        "#layer 1: 20 relu, layer 2: 20 relu(epochs = 2000)\n",
        "# 63/63 [==============================] - 0s 2ms/step\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#            0       0.78      0.62      0.69      1042\n",
        "#            1       0.66      0.81      0.73       958\n",
        "\n",
        "#     accuracy                           0.71      2000\n",
        "#    macro avg       0.72      0.72      0.71      2000\n",
        "# weighted avg       0.73      0.71      0.71      2000\n",
        "# 63/63 [==============================] - 0s 2ms/step\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#            0       0.73      0.70      0.71      1042\n",
        "#            1       0.69      0.71      0.70       958\n",
        "\n",
        "#     accuracy                           0.71      2000\n",
        "#    macro avg       0.71      0.71      0.71      2000\n",
        "# weighted avg       0.71      0.71      0.71      2000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fxlxD2Krn7l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8T84bCFvd1M"
      },
      "outputs": [],
      "source": [
        "draw_confusion_matrix(test_Y, test_Y_hat_cat, [1,0], \"confusion matrix: neural network\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_vK1bbgvfSq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}